# EEG Foundation Models Project (ALFEE + CBraMod + LaBraM + NeuroLM)

μ΄ ν”„λ΅μ νΈλ” ALFEE, CBraMod, LaBraM, NeuroLM λ„¤ κ°€μ§€ μ£Όμ” EEG Foundation Modelμ„ ν†µν•©ν•μ—¬, λ™μΌν• λ°μ΄ν„° μ²λ¦¬ νμ΄ν”„λΌμΈκ³Ό ν•™μµ ν”„λ μ„μ›ν¬ λ‚΄μ—μ„ μ„ νƒμ μΌλ΅ μ‚¬μ©ν•  μ μλ„λ΅ λ¦¬ν©ν† λ§ν• μµμΆ… λ²„μ „μ…λ‹λ‹¤.

## β¨ μ£Όμ” νΉμ§•

- **4κ° λ¨λΈ μ™„λ²½ μ§€μ›**: `config.yaml` νμΌ μμ •λ§μΌλ΅ **ALFEE**, **CBraMod**, **LaBraM**, **NeuroLM** λ¨λΈμ„ μ†μ‰½κ² κµμ²΄ν•μ—¬ ν•™μµ λ° ν‰κ°€ν•  μ μμµλ‹λ‹¤.
- **λ¨λΈλ³„ κ³ μ  ν•™μµ λ°©μ‹ μ§€μ›**:
  - **ALFEE**: Multi-Scale Conv, PSD νΉμ§• μ¶”μ¶, 4κ°€μ§€ μ†μ‹¤ ν•¨μ λ“± λ…Όλ¬Έμ λ¨λ“  ν•µμ‹¬ κΈ°λ¥μ„ ν¬ν•¨ν• Self-Supervised Pre-training -> Fine-tuning.
  - **CBraMod**: Supervised λ° Self-Supervised Pre-training -> Fine-tuning. **Criss-Cross Attention** λ° **λ¶„λ¥κΈ° μµμ…** μ§€μ›.
  - **LaBraM**: VQ-VAE κΈ°λ° μ±„λ„ λ§μ¤ν‚Ή Self-Supervised Pre-training -> Fine-tuning.
  - **NeuroLM**: EEG-Language Multi-modal Supervised Pre-training -> Fine-tuning.
- **μ‚¬μ „ ν•™μµλ κ°€μ¤‘μΉ μ¬ν™μ©**: CBraMod, LaBraM, NeuroLM μ›λ³Έ GitHubμ **`.pth` κ°€μ¤‘μΉλ¥Ό λ¶λ¬μ™€ νμΈνλ‹**ν•λ” κΈ°λ¥μ„ μ§€μ›ν•©λ‹λ‹¤.
- **κ³µμ©ν™”λ μ „μ²λ¦¬ νμ΄ν”„λΌμΈ**: λ¨λΈλ³„/λ°μ΄ν„°μ…‹λ³„ μ „μ²λ¦¬ λ΅μ§μ„ κ³µμ©ν™”ν•μ—¬ **λ™μΌν• λ°μ΄ν„°μ…‹μΌλ΅ μ—¬λ¬ λ¨λΈμ„ μ‰½κ² μ‹¤ν—**ν•  μ μμµλ‹λ‹¤.
- **Multi-modal λ°μ΄ν„° ν™•μ¥μ„±**: λ°μ΄ν„° νμ΄ν”„λΌμΈμ΄ EEG μ‹ νΈ μ™Έμ— ν…μ¤νΈ, νƒ€μ„μ¤νƒ¬ν”„ λ“± μ¶”κ°€μ μΈ λ©”νƒ€λ°μ΄ν„°λ¥Ό μ²λ¦¬ν•  μ μλ„λ΅ μ„¤κ³„λμ—μµλ‹λ‹¤.
- **μµμ‹  Lightning ν”„λ μ„μ›ν¬**: `pytorch_lightning` λ€μ‹  μµμ‹  `lightning.pytorch`λ¥Ό μ‚¬μ©ν•©λ‹λ‹¤.
- **μµμΆ… κ²€μ¦ μ¤ν¬λ¦½νΈ**: `dummy_train_test.py`λ¥Ό ν†µν•΄ λ„¤ κ°€μ§€ λ¨λΈ κ°κ°μ κ³ μ ν• μ „μ²΄ ν•™μµ/ν‰κ°€ νμ΄ν”„λΌμΈμ„ λ¨λ‘ κ²€μ¦ν•  μ μμµλ‹λ‹¤.

## π“‚ ν”„λ΅μ νΈ κµ¬μ΅°

```
eeg_foundation_models/
β”β”€β”€ configs/
β”‚   β””β”€β”€ default_config.yaml
β”β”€β”€ data_handling/
β”‚   β”β”€β”€ base_dataset.py
β”‚   β”β”€β”€ datasets.py
β”‚   β”β”€β”€ eeg_datamodule.py
β”‚   β””β”€β”€ preprocessing.py
β”β”€β”€ models/
β”‚   β”β”€β”€ alfee_architecture.py
β”‚   β”β”€β”€ cbramod_architecture.py
β”‚   β”β”€β”€ labram_architecture.py
β”‚   β”β”€β”€ neurolm_architecture.py
β”‚   β””β”€β”€ components.py
β”β”€β”€ elightning/
β”‚   β””β”€β”€ eeg_lightning_module.py
β”β”€β”€ main.py
β”β”€β”€ dummy_train_test.py
β”β”€β”€ requirements.txt
β””β”€β”€ README.md
```

## π€ μ‹¤ν–‰ λ°©λ²•

### 1. λ¨λΈ λ° ν•™μµ λ°©μ‹ μ„ νƒ
`configs/default_config.yaml` νμΌμ„ μ—΄κ³  `model_selection` λ° κ΄€λ ¨ ν•™μµ λ¨λ“ κ°’μ„ μ„¤μ •ν•©λ‹λ‹¤.

### 2. λ”λ―Έ λ°μ΄ν„°λ΅ μ „μ²΄ μ›ν¬ν”λ΅μ° κ²€μ¦ (κ°•λ ¥ μ¶”μ²)
λ¨λ“  ν•™μµ νμ΄ν”„λΌμΈμ΄ μ •μƒ λ™μ‘ν•λ”μ§€ λ‹¤μ λ…λ Ήμ–΄λ΅ μ¦‰μ‹ ν™•μΈν•  μ μμµλ‹λ‹¤.
```bash
python dummy_train_test.py
```

### 3. μ‹¤μ  λ°μ΄ν„°λ΅ ν•™μµ λ° ν‰κ°€
```bash
# μ‚¬μ „ν•™μµ (λ¨λΈλ³„ κ³ μ  λ°©μ‹ μλ™ μ μ©)
python main.py --mode pretrain --model [MODEL_NAME]

# μ΄ ν”„λ΅μ νΈμ—μ„ μ‚¬μ „ν•™μµν• λ¨λΈλ΅ νμΈνλ‹
python main.py --mode finetune --model [MODEL_NAME] --checkpoint_path "path/to/pretrained.ckpt"

# μ›λ³Έ κ°€μ¤‘μΉλ΅ νμΈνλ‹
python main.py --mode finetune --model [MODEL_NAME] --original_ckpt_path "path/to/original.pth"
```
